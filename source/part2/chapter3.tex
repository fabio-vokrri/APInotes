\chapter{Strutture Dati}
Gli insiemi manipolati dagli algoritmi, a differenza di quelli matematici, possono essere modificati inserendo o rimuovendo elementi. Questi insiemi sono detti dinamici e giocano un ruolo importante in informatica, perchè modellano le strutture utilizzate per memorizzare in modo ordinato i dati.

In una tipica implementazione di un insieme dinamico, ogni elemento è rappresentato da un oggetto, i cui attributi possono essere esaminati e manipolati a piacimento dagli algoritmi. In molte strutture dati, l'oggetto dispone di una chiave identificativa (spesso univoca, ma non necessariamente) e ovviamente di dati satelliti che si vogliono memorizzare ordinatamente in memoria. Oltre a questi due attributi, l'oggetto può anche contenere altri dati specifici per una determinata struttura dati, in modo da rendere più semplice e veloce la loro manipolazione.

Le tipiche operazioni che si possono svolgere sulle strutture dati sono suddivise in due categorie: le query (interrogazioni), che hanno il solo scopo di estrapolare informazioni dall'insieme dinamico, e le operazioni di modifica, che hanno il compito di modificare l'insieme. Di seguito sono elencate le istruzioni più comuni:

\begin{itemize}
  \item \code{search(S, k)}: è un'operazione di query che, dato un insieme \(S\) e un valore chiave \(k\), restituisce \code{NIL} se tale elemento non appartiene all'insieme.
  \item \code{insert(S, x)}: è un'operazione di modifica che inserisce all'interno dell'insieme \(S\) l'elemento puntato da \(x\).
  \item \code{delete(S, x)}: è un'operazione di modifica che, dato un puntatore \(x\) ad un elemento dell'insieme \(S\), rimuove \(x\) da \(S\).
  \item \code{minimum(S)}: è un'operazione di query che ritorna l'elemento dell'insieme \(S\) con la chiave più piccola.
  \item \code{maximum(S)}: è un'operazione di query che ritorna l'elemento dell'insieme \(S\) con la chiave più grande.
  \item \code{successor(S, x)}: è un'operazione di query che, dato un elemento \(x\) la cui chiave appartiene ad un insieme totalmente ordinato \(S\), restituisce un puntatore all'elemento successivo più grande di \(S\) oppure \code{NIL} se \(x\) è il più grande degli elementi.
  \item \code{predecessor(S, x)}: è un'operazione di query che, dato un elemento \(x\) la cui chiave appartiene ad un insieme totalmente ordinato \(S\), restituisce un puntatore all'elemento precedente più piccolo di \(S\) oppure \code{NIL} se \(x\) è il più piccolo degli elementi.
\end{itemize}

\section{Stack}
Gli \textbf{stack} sono insiemi dinamici dove l'elemento da rimuovere tramite l'operazione \code{delete} è predeterminato. In questa struttura dati, l'elemento cancellato è quello inserito per ultimo, secondo la politica LIFO (Last In, First Out). Nello specifico, le operazioni di \code{insert} e \code{delete} prendono rispettivamente il nome di \code{push} e \code{pop} \footnote{Questa operazione non prende nessun argomento, in quanto l'elemento da eliminare è predeterminato}: la prima inserisce in cima alla pila l'elemento passato come argomento, mentre la seconda operazione elimina l'unico elemento accessibile dalla pila, ovvero la cima. 

Questa struttura dati può essere implementata tramite un array con un massimo di \(n\) elementi \code{S[1..n]}, che presenta lo specifico atrtibuto \code{S.top}, ovvero l'indice tramite cui accedere all'ultimo elemento inserito. L'array è dunque composto dagli elementi \code{S[1..S.top]}, dove \code{S[1]} rappresenta l'elemento in fondo alla pila, mentre \code{S[S.top]} rappresenta l'elemento in cima. Ovviamente, se \code{S.top} = 0, si dice che la pila è vuota, in quanto non contiene nessun elemento. In questo caso, se si tenta di estrarre un elemento dallo stack, si ottiene un errore di underflow dello stack, mentre se si cerca di inserire un elemento sulla pila piena (che conta quindi di \(n\) elementi), si ottiene un errore di overflow dello stack.

Le operazioni dello stack possono essere implementate molto semplicemente in pseudocodifica come segue:
\lstinputlisting{../docs/data_structures/stack_push.txt}

\lstinputlisting{../docs/data_structures/stack_pop.txt}

Si noti come, in questo caso, l'operazione di \code{pop} ritorna l'elemento appena eliminato dallo stack. Entrambe le procedure vengono eseguite in tempo costante \(\Theta(1)\).

\section{Queue}
Le \textbf{code} sono insiemi dinamici dove l'elemento da rimuovere tramite l'operazione \code{delete} è predeterminato. In questa struttura dati, l'elemento cancellato è quello inserito per primo, secondo la politica FIFO (First In First Out). Nello specifico, la coda presenta un inizio detto \code{head} e una fine detta \code{tail}, e le operazioni di \code{insert} e \code{delete} prendono rispettivamente il nome di \code{enqueue} e \code{dequeue} \footnote{Anche in questo caso, questa operazione non prende nessun argomento, in quanto l'elemento da eliminare è predeterminato}: la prima inserisce in fondo alla fila l'elemento passato come argomento, mentre la seconda operazione elimina il primo elemento della fila. 

Questa struttura dati può essere implementata tramite un array di \(n\) elementi \code{Q[1..n]}, che contiene un massimo di \(n-1\) elementi, per ragioni che verranno chiarite in seguito. L'attributo \code{Q.head} punta all'inizio della coda, mentre l'attributo \code{Q.tail} punta alla posizione in cui l'ultimo elemento che dovrà essere inserito prenderà posto (ovvero alla posiziove vuota successiva all'ultimo elemento della coda). Gli elementi della coda, quindi, occupano le posizioni \code{Q.head}, \code{Q.head + 1}, ..., \code{Q.tail - 1}. Alla fine dell'array la posizione 1 della queue segue immediatamete la posizione \(n\) secondo un ordine circolare. Se \code{Q.head = Q.tail} allora la coda è vuota. All'inizio le posizioni \code{Q.head} e \code{Q.tail} combaciano e sono entrambe inizializzate al valore 1.

Come per gli stack, se la coda è vuota, il tentativo di rimuovere un elemento provoca un errore di underflow, mentre se \code{Q.head = Q.tail + 1} la coda è piena e il tentativo di inserire un nuovo elemento provoca un errore di overflow. 

Le operazioni della queue possono essere implementate molto semplicemente in pseudocodifica come segue:

\lstinputlisting{../docs/data_structures/queue_enqueue.txt}

\lstinputlisting{../docs/data_structures/queue_dequeue.txt}

Entrambe le procedure vengono eseguite in un tempo costante \(\Theta(1)\).

\section{Linked List}
Una \textbf{lista concatenata} è una struttura dati i cui oggetti sono disposti in ordine lineare, determinato da un puntatore in ogni oggetto. Una lista doppiamente concatenata è una lista in cui ogni oggetto presenta, oltre ad una chiave \code{key}, anche un puntatore all'elemento successivo \code{next} e un puntatore a quello precedente \code{prev}. Se \code{x.prev = NIL}, allora l'elemento \(x\) è il primo elemento della lista e si dice essere la testa (o head) della lista. Se, invece, \code{x.next = NIL}, allora \(x\) è l'ultimo elemento della lista e si dice essere la coda (o tail) della lista. Intuitivamente, l'attributo \code{L.head} punta alla testa della lista, che sarà vuota se \code{L.head = NIL}.

Questa struttura dati può presentare varie forme: può essere doppiamente concatenata o singolarmente concatenata, oppure può essere circolare o non. Una lista si dice singolarmente concatenata se i suoi oggetti non sono dotati di puntatore all'elemento precedente, mentre si dicono circolari se l'ultimo elemento possiede un puntatore alla testa della lista, che a sua volta possiede un puntatore alla coda se la lista è circolare. Una lista concatenata può anche essere ordinata o non: si dice ordinata quando la disposizione lineare degli elementi corrisponde con la disposizione crescente delle chiavi degli elementi e, in tal caso, la testa della lista conterrà l'elemento minimo, mentre la coda l'elemento massimo. 

Nel seguito si fa riferimento a liste non ordinate doppiamente concatenate per lo sviluppo degli algoritmi che le manipolano. 

\paragraph{Ricerca}
La prima procedura che sia analizza è \code{listSearch(L, k)}, che trova il primo elemento con la chiave \(k\) nella lista \(L\), restituendo un puntatore a tale oggetto. Se nessun oggetto con chiave \(k\) è presente nella lista, allora viene restituito il valore \code{NIL}. In pseudocodifica:

\lstinputlisting{../docs/data_structures/list_search.txt}

Si noti quindi che l'algoritmo \code{listSearch} cerca l'elemento di chiave \(k\) tramite una ricerca lineare sulla list \(L\) di \(n\) elementi. Dunque, l'algoritmo impiega un tempo \(\Theta(n)\) nel caso peggiore, in quanto potrebbe essere necessario scorrere l'intera lista.

\paragraph{Inserimento}
La seconda procedura analizzata è \code{listInsert(L, x)} che inserisce l'elemento x di attributo key (già inizializzato) in testa alla lista. In pseudocodifica:

\lstinputlisting{../docs/data_structures/list_insert.txt}

Questa procedura impiega un tempo costante \(\Theta(1)\) per la sua esecuzione.

\paragraph{Rimozione}
L'ultima procedura analizzata per le linked list è \code{listDelete(L, x)}, che rimuove l'elemento \(x\) dalla lista \(L\). Per poter eliminare tale elemento è prima necessario chiamare la funzione \code{listSearch} per ottenere il puntatore all'elemento desiderato. In pseudocodifica:

\lstinputlisting{../docs/data_structures/list_delete.txt}

Anche questa procedura impiega un tempo di esecuzione \(\Theta(1)\).

\section{Hash Table}
\subsection{Indirizzamento diretto}
Prima di procedere con l'introduzione alle tavole di hash, è prima necessario introdurre il concetto di indirizzamento diretto, una tecnica molto efficiente nel caso in cui l'insieme da cui vengono acquisite le chiavi, detto insieme universo \(U = \{0,1,2...,m-1\}\), è un insieme ragionevolmente piccolo. Si suppone, inoltre, che due elementi distinti non possano avere chiavi coincidenti. Per rappresentare un tale insieme dinamico si utilizza un array, oppure una tavola ad indirizzamento diretto, indicata con \(T[0..m-1]\), dove ogni cella \(k\) di tale tabella punta all'elemento dell'insieme di chiave \(k\). Se la \(k\)-esima cella non contiene nessun elemento, viene inizializzata con il valore \code{NIL}.

Le operazioni di dizionario sono semplici da implementare in pseudocodifica e impiegano tutte un tempo costante \(O(1)\) (nel caso peggiore):

\begin{lstlisting}
directAddressSearch(T, k):
  return T[k]
\end{lstlisting}

\begin{lstlisting}
directAddressInsert(T, x):
  T[x.key] := x 
\end{lstlisting}

\begin{lstlisting}
directAddressDelete(T, x):
  T[x.key] := NIL
\end{lstlisting}

In alcune implementazioni è possibile memorizzare l'elemento di chiave \(k\) direttamente all'interno della tabella, anzichè in un oggetto esterno, risparmiando spazio in memoria. 

\subsection{Introduzione alle Tavole di Hash}

La difficoltà nell'implementazione di una tale struttura dati è evidente: l'insieme universo \(U\), nella maggior parte dei casi, è troppo grande per essere memorizzato in una tavola \(T\) di dimensione \(|U|\). Inoltre, l'insieme \(K\) delle chiavi effettivamente memorizzate è molto più piccolo dell'inisieme \(U\) delle chiavi disponibili e, dunque, la maggior parte dello spazio allocato per la tavola \(T\) non verrebbe mai utilizzato. A questo proposito si introduce una nuova struttura dati, detta \textbf{tavola di hash}, che utilizza una memoria proporzionale al numero delle chiavi effettivamente memorizzate nel dizionario, riducendo lo spreco di memoria. 

Quando l'insieme \(K\) delle chiavi memorizzate in un dizionario è molto più piccolo dell'universo \(U\) di tutte le chiavi possibili, utilizzando una tavola di hash si può ridurre lo spazio richiesto fino a \(\Theta(|K|)\), rdiucendo però l'efficienza temporale a \(O(1)\) nel caso medio (anzichè pessimo). Nella tabella di hash, l'elemento di chiave \(k\) non viene memorizzato direttamente nella cella \(k\), ma viene utilizzata una cosiddetta funzione di hash \(h(k)\) che calcola l'indice \(k\) della cella. La funzione di hash \(h(k)\) associa ad ogni chiave dell'universo \(U\) una specifica chiave della tavola di hash \(T[0..m-1]\). Formalmente:

\(h(k):U\to \{0,1,..., m-1\},\;\;\; m<<|U|\)

Si dice che \(h(k)\) è il valore hash della chiave \(k\).

\subsection{Hashing Concatenato}

Il problema principale con la tecnica di indirizzamento appena analizzata è che, riducendo l'intervallo degli indici da \(|U|\) ad \(m<<|U|\), è molto probabile che due chiavi vengano mappate nella stessa cella: in tal caso si dice che avviene una collisione. Per evitare un evento simile è possibile, in prima analisi, implementare una funzione di hash totalmente deterministica il più randomica possibile, in modo da minimizzare le collisioni. Si dimostra però che un evento di collisione è impossibile da evitare in quanto \(|U| > m\) e quindi, dopo l'\(m\)-esima chiamata alla funzione di hash, avverà sicuramente una collisione. 

Si rende necessario, dunque, implementare un meccanismo che gestisca tali eventi. Nello specifico, la tecnica più utilizzata è il concatenamento (o chaining), tramite cui, tutti gli elementi associati ad una stessa cella \(k\) sono posti in una lista concatenata. La cella \(k\), in questo caso, punta al nodo di testa della lista che contiene gli elementi mappati in tale cella, oppure ha valore \code{NIL}, nel caso in cui la cella non contenga nessun elemento. 

Le operazioni di dizionario su una tavola di hash \(T\) sono facili da implementare in pseudocodifica nel caso di gestione delle collisioni tramite concatenamento:

\begin{lstlisting}
chainedHashInsert(T, x):
  listInsert(T[h(x.key)], x)
\end{lstlisting}

\begin{lstlisting}
chainedHashSearch(T, x):
  listSearch(T[h(x.key)], x)
\end{lstlisting}

\begin{lstlisting}
chainedHashDelete(T, x):
  listDelete(T[h(x.key)])
\end{lstlisting}

In cui le procedure \code{listInsert}, \code{listSearch} e \code{listDelete}, sono le stesse analizzate nella sezione delle liste concatenate e hanno il compito, rispettivamente, di inserire in testa alla lista un nodo, cercare un nodo nella lista ed eliminare un nodo dalla lista. 

Si passa ora all'analisi del tempo di esecuzione di tali procedure: nel caso peggiore, l'inserimento in lista di un nodo è \(O(1)\), la ricerca avviene in tempo proporzionale alla lunghezza della lista, quindi \(O(n)\), mentre l'eliminazione di un nodo dalla lista avviene, sempre nel caso peggiore, in tempo \(O(1)\) se la lista è doppiamente concatenata. 

Si noti che la funzione \code{chainedHashDelete} prende come input un elemento \(x\), non la sua chiave \(k\), quindi non occorre cercare prima l'elemento \(x\). Se la tavola di hash supporta la cancellazione, allora le sue liste dovrebbero essere doppiamente concatenate in modo che la cancellazione di un elemento sia più rapida. Se le liste fossero singolarmente concatenate, per cancellare l'elemento \(x\), si dovrebbe prima trovare \(x\) nella lista \(T[h(x.key)]\) in modo da poter aggiornare l'attributo \code{next} dell'elemento precedente in lista, assegnandogli il valore \code{NIL}.

\subsection{Analisi della Funzione di Hash}
Data una tavola di hash \(T\), che conta \(m\) celle in cui sono memorizzati \(n\) elementi, si definisce il fattore di carico \(\alpha\) della tavola \(T\) come il rapporto \(n/m\), ossia il numero medio di elementi memorizzati in una lista. Il caso peggiore nell'hashing si verifica quando tutte le \(n\) chiavi sono associate alla stessa cella, creando una lista di lunghezza \(n\). Il tempo di esecuzione della ricerca diventa quindi \(\Theta(n)\) a cui si aggiunge il tempo di esecuzione della funzione di hashing. Ovviamente, un caso del genere è molto improbabile nel caso in cui la funzione di hash sia ben progettata. Per il momento si suppone che ogni elemento ha uguale probabilità di essere mappato in una qualsiasi delle \(m\) celle, indipendentemente dalle celle in cui sono stati mappati gli altri elementi. Tale ipotesi viene definita hashing uniforme semplice. Per ogni \(j=0,1,..., m-1\), si indica con \(n_j\) la lunghezza della lista \(T[j]\), ottenendo quindi il numero di elementi totali memorizzati in tabella è \(n=n_0+n_1+...+n_{m-1}\). Il valore atteso di ogni \(n_j\) sarà \(E[n_j] = \alpha = n/m\), quindi il tempo medio per la ricerca di un elemento di chiave \(k\) non presente nella lista (caso pessimo) è \(\Theta(1+\alpha)\), che si dimostra essere anche il tempo di ricerca dello stesso elemento, questa volta presente tabella. Nella pratica, se il numero di celle nella tavola di hash è almeno proporzionale al numero di elementi della tavola, si ottiene che \(n=O(m)\) e quindi \(\alpha = n/m = O(m)/m = O(1)\). Pertanto, la ricerca di un elemento della tavola richiede un tempo costante.Ogni operazione di dizionario può essere svolta, in media, in un tempo \(O(1)\).

\subsection{Funzione di Hash}
Per progettare una buona tabella di hash è necessario implementare una funzione di hash che sia altamente efficiente. A questo proposito si introducono tre possibili schemi di implementazione: hashing per divisione (uristico), hashing per moltiplicazione (euristico) e hashing universale (aleatorio, non analizzato in questa sezione). In generale, una buona funzione di hashing deve soddisfare approssimativamente la condizione di hashing uniforme semplice: ogni chiave deve avere la stessa probabilità di essere mappata in una qualsiasi cella della tabella. Di solito non è possibile verificare questa condizione, in quanto non è nota la distribuzione delle probabilità secondo cui vengono estratte le chiavi. Quindi, nella pratica, spesso si utilizzano delle tecniche euristiche per la realizzazione di tali funzioni.

La maggior parte delle funzioni di hashing suppone che l'universo delle chiavi sia l'insieme dei numeri naturali \(\mathbb{N}\) e quindi, se nella struttura dati progettata, la chiave non è un numero naturale ma, ad esempio, una stringa, è necessario studiare un metodo di conversione: nei calcolatori questo metodo è tipicamente già implementato, in quanto ogni informazione analogica viene convertita in una stringa binaria di bit (appartenente ad \(\mathbb{N}\)). Nello studio dei tre metodi di hashing si suppone che le chiavi siano numeri naturali.

\paragraph{Metodo della Divisione} Quando si applica il metodo della divisione per creare una funzione di hash, una chiave \(k\) viene associata a una delle \(m\) celle prendeno il resto della divisione fra \(k\) ed \(m\). Formalmente, la funzione di hash è così definita:

\(h(k)=k\; mod\; m\)

\noindent Il vantaggio principale di questo metodo è che si può implementare molto rapidamente e richiede un tempo di esecuzione costante. 

Quando si utilizza il metodo della divisione, si cerca di evitare alcuni valori di \(m\). Nello specifico si evitano le potenze di 2, in quanto se \(m=2^p\), allora \(h(k)\) rappresenta proprio i \(p\) bit meno significativi di \(k\): infatti, sarebbe più corretto far dipendere la funzione di hash da tutti i bit della chiave. Inoltre, si evita di scegliere \(m+2^p-1\) quando \(k\) è una stringa di caratteri interpretata in base \(2^p\), in quanto la permutazione dei caratteri di \(k\) non cambia il suo valore di hash. Una buona scelta di \(m\), invece, potrebbe essere un numero primo non troppo vicino a una potenza esatta di 2.

\paragraph{Metodo della Moltiplicazione} Il metodo della moltiplicazione per la creazione di funzioni di hash consiste in due passi. Nel primo passaggio si moltiplica la chiave \(k\) per una costante \(A\), tale che \(0<A<1\), per poi estrarre la parte frazionaria del numero appena ottenuto. Nel secondo passaggio si moltiplica questo valore per \(m\) e si prende la parte intera inferiore del risultato. Formalmente, la funzione di hash è così definita:

\(h(k) = \lfloor m\,(k\cdot A\;mod\;1)\rfloor\)

\noindent dove \(k\cdot A \; mod \;1 \) rappresenta la parte frazionaria di \(kA\), ovvero \(kA-\lfloor kA\rfloor\). 

Il vantaggio principale di questo metodo è che il valore di \(m\) non è critico. Tipicamente si sceglie un valore di \(m\) tale per cui sia una potenza di 2, in modo da rendere più semplice implementare tale funzione in un calcolatore reale. Si upponga, infatti, che la dimensione di una parola nel calcolatore sia \(w\) bit e che il numero \(k\) sia contenuto in una sola parola. Si scelga poi un valore di \(A\) che sia una frazione nella forma \(s/2^w\), con \(s\) intero nell'intervallo \(0<s<2^w\). A questo punto, si moltiplica \(k\) per \(s=A\cdot 2^w\): il risultato sarà un numero di \(2w\) bit \(r_1 2^w+r_0\), in cui \(r_1\) rappresenta la parte più significativa del prodotto ed \(r_0\) la parte meno significativa. Il valore hash desiderato di \(p\) bit è formato dai \(p\) bit più significativi di \(r_0\). Sebbene queste operazioni funzionino con qualsiasi valore della costante \(A\), la scelta spesso adoperata è \(A \approx (\sqrt{5}-1)/2 \approx 0.6180339887...\)

\subsection{Indirizzamento Aperto}
Un altro metodo per evitare le collisioni è tramite l'indirizzamento aperto, in cui tutti gli elementi sono memorizzati nella tavola hash, ovvero ogni cella contiene un elemento dell'insieme dinamico o la costante \code{NIL} se non contiene nessun elemento. Quando si cerca un elemento, si esamina sistematicamente la tabella fino a quando non si trova l'elemento desiderato, oppure finchè non ci sono più elementi da controllare (l'elemento non è nell'array). Nell'indirizzamento aperto, a differenza degli altri metodi, la tavola hash può riempirsi fino a quando non può più fisicamente contenere altri elementi. Una conseguenza di questo design è che il fattore di carico \(\alpha\) non supera mai il valore 1. Il vantaggio di questo metodo sta nel fatto che elimina completamente l'utilizzo dei puntatori, in quanto calcola la sequenza delle celle da esaminare, e libera quindi una notevole quantità di memoria, utilizzata per incrementare la capacità della tabella, riducendo il rischio di collisioni. 

\paragraph{Inserimento}
Per effettuare un insierimento mediante il metodo dell'indirizzamento aperto, si esamina in successione le posizioni della tavola hash fino a che non si trova una cella libera in cui inserire la chiave. L'efficienza di questo metodo consiste nel calcolare una nuova sequenza di accesso alla tabella in base alla chiave dell'oggetto da inserire, anzichè seguire sempre lo stesso cammino di accessi, che impiegherebbe un tempo di esecuzione \(\Theta(n)\). Per determinare quali celle esaminare durante la fase di ispezione, si estende la funzione di hash in modo da includere l'ordine di ispezione (a partire da 0), come secondo input. Formalmente, la funzione di hash modificata è definita come segue:

\(h(k,i):U\times \{0,1,...,m-1\} \to \{0,1,...,m-1\}\)

\noindent Si richiede, inoltre, che per ogni chiave \(k\) la sequenza di ispezione \(<h(k,0), h(k,1),..., h(k,m-1)>\) sia una permutazione della sequenza \(<0,1,...,m-1>\), in modo tale che ogni cella della tavola possa essere considerata come possibile cella in cui inserire una nuova chiave. In pseudocodifica:

\lstinputlisting{../docs/data_structures/hash_insert.txt}

Questa procedura prende in input una tavola di hash \(T\) e una chiave \(k\) da inserire in tabella, e ritorna l'indice della cella in cui è stato inserito l'elemento, oppure \code{error} di overflow se non è presente nessuna cella libera. Si noti nella condizione in riga 5, che viene verificato se la cella \(T[k]\) contiene il valore \code{DELETED}: questo valore speciale verrà ripreso e analizzato più avanti assieme alla procedura di eliminazione delle chiavi dalla tabella.

\paragraph{Ricerca}
Per la ricerca di una determinata chiave \(k\) esamina la stessa sequenza di celle che ha esaminato l'algoritmo di inserimento quando ha inserito l'elemento di chiave \(k\). Dunque, la procedura di ricerca potrebbe terminare la propria esecuzione senza successo quando trova una cella vuota, in quanto la chiave \(k\) sarebbe stata inserita in quella posizione (si presuppone che le chiavi non possano essere eliminate dalla tavola). In pseudocodifica:

\lstinputlisting{../docs/data_structures/hash_search.txt}

Questa procedura, come la precedente, prende in input una tavola di hash \(T\) e una chiave \(k\) da ricercare in tabella, e ritorna l'indice della cella in cui è stato trovato l'elemento, oppure \code{NIL} se non è presente nessuna cella che contiene l'elemento oppure se nella sequenza di ricerca si trova una cella libera (per le ragioni precedentemente analizzate).

\paragraph{Rimozione}
La procedura di cancellazione di una chiave dalla tavola di hash ad indirizzamento aperto è un'operazione molto complessa, in quanto non è possibile semplicemente cancellare il contenuto della cella \(i\), assegnandone il valore \code{NIL}, in quanto sarebbe impossibile ricercare qualsiasi elemento in tabella per come è stata definita la procedura di ricerca. Dunque, si rende necessario marcare la cella il cui contenuto è stato eliminato con il valore speciale \code{DELETED}, anzichè \code{NIL}. È per questo motivo che in riga 5 della procedura di inserimento viene anche verificato se la cella ispezionata contanga il valore \code{DELETED}. Si noti inoltre che, utilizzando questa nuova notazione, il tempo di esecuzione della procedura di ricerca non dipende più dal fattore di carico \(\alpha\). Per questo motivo, nella pratica si preferisce spesso utilizzare il metodo della concatenazione quando è necessario che la tabella di hash supporti l'operazione di cancellazione delle chiavi. 

\subsection{Hashing Uniforme}
Nell'analisi delle tabelle hash con indirizzamento aperto si ipotizza hashing uniforme: si suppone, infatti, che ogni chiave abbia la stessa probabilità di avere come sequenza di ispezione una delle \(m!\) permutazioni di \(<0,1,...,m-1>\). L'hashing uniforme estende il concetto di hashing uniforme semplice, impiegato più volte precedentemente, al caso in cui la funzione di hash produce, non un singolo numero, ma un'intera sequenza di ispezione. Nella pratica non è possibile ottenere una funzione di hash uniforme, ma si utilizzano delle approssimazioni accettabili. Si esaminano nel seguito tre tecniche utilizzate per calcolare le sequenze di ispezione richieste nell'indirizzamento aperto: ispezione lineare, ispezione quadratica e doppio hashing. Tali tecniche grantiscono che la sequenza \(<h(k,0), h(k,1),..., h(k,m-1)>\) sia una permutazione di \(<0,1,...,m-1>\) per ogni chiave \(k\), ma nessuna di loro può garantire l'ipotesi di hashing uniforme, in quanto nessuna di esse è in grado di generare più di \(m^2\) sequenze di ispezioni differenti (invece delle \(m!\) sequenze richieste). 

\paragraph{Ispezione Lineare}
Data una funzione di hash ordinaria \(h':U\to \{0,1,...,m-1\}\), detta funzione di hash ausiliaria, il metodo di ispezione lineare utilizza la funzione di hash

\(h(k,i)=(h'(k)+i)\;mod\;m\)

\noindent per \(i=0,1,...,m-1\). Data la chiave \(k\), la prima cella esaminata è \(T[h'(k)]\), che è la cella data dalla funzione di hash ausiliaria, la seconda cella è \(T[h'(k)+1]\) e così via fino alla cella \(T[m-1]\). Poi, l'ispezione riprende dalle celle \(T[0], T[1],...,T[h'(k)-1]\). Poichè la prima cella ispezionata determina l'intera sequenza di ispezioni, ci sono soltanto \(m\) sequenze di ispezione distinte. Questa tecnica è facile da implementare ma presenta un problema noto come addensamento primario: si formano lunghe file di celle occupate che aumentano il tempo medio di ricerca. Tale fenomeno si presenta perchè una cella vuota preceduta da \(i\) celle piene ha probabilità \((i+1)/m\) di essere la prossima ad essere occupata e le lunghe file di celle occupate tendono, dunque, a diventare sempre più lunghe.

\paragraph{Ispezione Quadratica} Data la funzione di hash ausiliaria \(h':U\to \{0,1,...,m-1\}\), il metodo di ispezione qudratica utilizza la funzione di hash

\(h(k,i)=(h'(k)+c_1i+c_2i^2)\;mod\;m\)

\noindent per \(i=0,1,...,m-1\), con \(c_1, c_2 \neq 0 \) costanti ausiliarie. Data la chiave \(k\), la prima cella esaminata è \(T[h'(k)]\), mentre le successive posizioni esaminate sono distanti dalle precedenti di quantità che dipendono in modo quadratico dal numero d'ordine di ispezione \(i\). Questa tecnica funziona meglio della precedente, ma i valori \(c_1, c_2\) ed \(m\) non possono essere scelti in maniera arbitraria, ma devono essere tali per cui si possa percorrere l'intera tabella. Inolte, se due chiavi hanno la stessa posizione iniziale di ispezione, allora le due sequenze di ispezione saranno identiche portando al cosiddetto addensamento secondario.

\paragraph{Doppio Hashing} Date la funzioni di hash ausiliarie \(h_1\) ed \(h_2\), il metodo di ispezione lineare utilizza la funzione di hash

\(h(k,1) = (h_1(k)+ih_2(k))\;mod\;m\)

\noindent per \(i=0,1,...,m-1\). Il doppio hashing è il metodo migliore disponibile per l'indirizzamento aperto, in quanto le permutazioni prodotte hanno molte caratteristiche comuni con le permutazioni casuali. Data la chiave \(k\), la prima cella esaminata è \(T[h_1(k)]\), mentre le successive posizioni sono distanziate dalle precedenti di quantità \(h_2(k)\;mod\;m\). Differentemente dai precedenti, il metodo del doppio hashing produce sequenze che dipendono in due modi dalla chiave \(k\), in quanto possono variare sia la posizione iniziale della sequenza di ispezione, sia la distanza fra due posizioni successive. 

Inoltre, il valore \(h_2(k)\) deve essere relativamente primo con la dimensione \(m\) della tavola hash perchè venga ispezionata l'intera tabella. Un modo pratico per garantire tale condizione è scegliere \(m\) potenza di due e definire \(h_2\) in modo che produca sempre un numero dispari. Un altro modo è scegliere \(m\) primo e definire \(h_2\) in modo che generi sempre un numero intero positivo minore di \(m\). In questo contesto, il doppio hashing è migliore delle precedenti tecniche in quanto utilizza \(\Theta(m^2)\) sequenze di ispezione, anzichè \(\Theta(m)\), perchè ogni possibile coppia di \(h_1, h_2\) produce una distinta sequenza di ispezione.

\section{Alberi Binari}
Un albero binario di ricerca è una struttura dati ad albero\footnote{consultare appendice A per approfondire la definizione di struttura dati ad albero.} che supporta molte operazioni degli insiemi dinamici, come \code{search}. \code{delete}, \code{insert}, \code{minimum}, \code{maximum}, \code{successor} e \code{predecessor}. Tali alberi sono rappresentati da strutture concatenate in cui ogni nodo è un oggetto, che oltre ad avere una chiave e i dati satellite, contengono anche gli attributi \code{left}, \code{right} e \code{parent}, che puntano rispettivamente al figlio sinistro, al figlio destro e al padre. Se manca un figlio o un padre, i corrispondenti attributi sono inizializzati a \code{NIL}. Il nodo radice, detto anche root, è l'unico nodo nell'albero il cui attributo padre è inizializzato con \code{NIL}.

Le chiavi dell'albero binario di ricerca sono memorizzate in maniera da rispettare sempre la proprietà fondamentale per cui se \(x\) è un nodo in un albero binario di ricerca ed \(y\) è il nodo nel sottoalbero sinistro di \(x\), allora \(y.key \le x.key\), mentre se \(y\) è un nodo nel sottoalbero destro di \(x\), allora \(y.key \ge x.key\). Tale proprietà permette di elencare ordinatamente tutte le chiavi di un albero binario di ricerca con un semplice algoritmo ricorsivo di attraversamento simmetrico di un albero, tramite cui la chiave della radice di un sottoalbero viene stampata nel mezzo tra la stampa dei valori nel sottoalbero sinistro e la stampa dei valori nel sottoalbero destro. In pseudocodice:

\lstinputlisting{../docs/data_structures/tree_inorder.txt}

Per attraversare un albero binario di ricerca costituito da \(n\) nodi, è necessario un tempo \(\Theta(n)\), in quanto, dopo la chiamata iniziale, la procedura viene chiamata ricorsivamente esattamente due volte per ogni nodo dell'albero. 

\paragraph{Ricerca}
Un'altra tipica operazione svolta su un albero binario di ricerca è quella di cercare una chiave memorizzata nell'albero: oltre all'operazione \code{search}, gli alberi binari supportano anche query come \code{minimum}, \code{maximum}, \code{successor} e \code{predecessor}. 

Dato un puntatore alla radice dell'albero e una chiave \(k\) da cercare, la procedura \code{treeSearch} restituisce il puntatore al nodo di chiave \(k\), se esiste, oppure \code{NIL}, se la chiave non è presente nell'albero. In pseudocodifica:

\lstinputlisting{../docs/data_structures/tree_search.txt}

Questo algoritmo inizia la sua ricerca dalla radice dell'albero e ad ogni iterazione confronta il valore \(k\) passato come argomento con \(x.key\). Se le due chiavi sono uguali la ricerca termina e viene restituito il puntatore al nodo, mentre se la chiave è minore della chiave corrente analizzata, per la proprietà fondamentale degli alberi binari, si chiama ricorsivamente la procedura sul sottoalbero sinistro, altrimenti sul sottoalbero destro. Il tempo di esecuzione di tale algoritmo è \(O(h)\), dove \(h\) rappresenta l'altezza dell'albero. 

\paragraph{Minimo e Massimo}
Un elemento con chiave minima in un albero binario di ricerca può sempre essere trovato seguendo, a partire dalla radice, i puntatori \code{left}, fino a quando non viene incontrato un valore \code{NIL}, sempre per la proprietà fondamentale degli alberi binari di ricerca. In pseudocodifica:

\lstinputlisting{../docs/data_structures/tree_minimum.txt}

La procedura per trovare l'elemento massimo, invece, è simmetrica alla procedura appena analizzata. In pseudocodifica:

\lstinputlisting{../docs/data_structures/tree_maximum.txt}

Entrambe queste procedure vengono eseguite in un tempo \(O(h)\), in un albero di altezza h. 

\paragraph{Successore e Predecessore}
Dato un nodo in un albero binario di ricerca, spesso è necessario trovare il suo successore, nell'ordine stabilito da un attraversamento simmetrico. Il successore di un nodo \(x\) è il nodo con la più piccola chiave maggiore di \(x.key\). La struttura di un albero binario consente di trovare tale nodo senza il bisogno di confrontare le chiavi. In pseudocodifica:

\lstinputlisting{../docs/data_structures/tree_successor.txt}

Se il sottoalbero destro del nodo \(x\) non è vuoto, allora il successore di \(x\) è proprio il nodo più a sinistra nel sottoalbero destro, che viene trovato chiamando la procedura precedentemente analizzata \code{treeMinimum}. Altrimenti, se il sottoalbero destro del nodo \(x\) è vuoto e \(x\) ha un successore \(y\), allora \(y\) è l'antenato più prossimo di \(x\) il cui figlio sinistro è anche antenato di \(x\). Per trovare il nodo \(y\), è necessario risalire l'albero partendo da \(x\), fino a quando non si trova un nodo che è figlio sinistro di suo padre. Questa operazione è svolta in un tempo \(O(h)\), con \(h\) l'altezza dell'albero. 

La procedura per trovare il successore è simmetrica alla procedura appena anlizzata e viene svolta nello stesso tempo. 

\paragraph{Inserimento}
Per inserire un nuovo valore \(v\) all'interno dell'albero binario di ricerca \(T\), si utilizza la seguente procedura, che riceve in input un nodo \(z\), tale per cui \(z.key = v\):

\lstinputlisting{../docs/data_structures/tree_insert.txt}

La procedura appena vista inizia dalla radice dell'albero e il puntatore \(x\) traccia un cammino semplice in discesa cercando un \code{NIL} da sostituire con l'elemento di input \(z\). La procedura mantiene anche un puntatore \(y\) detto inseguitore che punta sempre al padre di \(x\). Le righe 4-9 del ciclo \code{while} spostano questi due puntatori verso il basso, andando a sinistra o a destra a seconda dell'esito del confronto fra \({z.key}\) e \(x.key\), finchè a \(x\) non viene assegnato il valore \code{NIL}. A questo punto si rende necessario il puntatore \(y\) perchè, quando si arriva a trovare il valore \code{NIL} da sostituire con il nodo \(z\), la ricerca è andata un passo oltre il nodo che deve essere modificato. Le righe successive inseriscono il nodo passato come argomento all'interno dell'albero binario di ricerca. In generale, questo algoritmo viene eseguito in un tempo \(O(h)\), in un albero di altezza \(h\).

\paragraph{Cancellazione}
La procedura per la cancellazione di un nodo \(z\) da un albero binario di ricerca si suddivide in tre casi:
\begin{enumerate}
  \item se il nodo \(z\) non ha figli, si modifica il nodo \(z.parent\) in modo che non punti più a \(z\), ma a \code{NIL};
  \item Se il nodo \(z\) ha un solo figlio, si eleva il figlio di tale nodo in modo che occupi la posizione di \(z\) nell'albero, modificando il padre di \(z\) affinchè punti al figlio di \(z\);
  \item Se il nodo \(z\) ha due figli, si trova prima di tutto il successore \(y\) di \(z\), che deve necessariamente trovarsi nel sottoalbero destro di \(z\), per poi fare in modo che \(y\) assuma la posizione di \(z\) nell'albero. La parte restante del sottoalbero destro originale diventa il nuovo sottoalbero destro di \(y\) e il sottoalbero sinistro di \(z\) diventa il nuovo sottoalbero sinistro di \(y\).
\end{enumerate}

Per poter spostare i sottoalberi all'interno dell'albero binario di ricerca si deve prima definire una procedura che sostituisca il sottoalbero figlio di suo padre con un altro sottoalbero. Questa procedura sosituisce il sottoalbero con radice nel nodo \(u\) con il sottoalbero con radice nel nodo \(v\), in modo che il padre del nodo \(u\) diventa il padre del nodo \(v\). In pseudocodifica:

\lstinputlisting{../docs/data_structures/tree_transplant.txt}

Una volta introdotto questo algoritmo, è possibile ora analizzare la procedura di eliminazione:

\lstinputlisting{../docs/data_structures/tree_delete.txt}

Questa procedura gestisce i tre casi analizzati precedentemente. Le righe 2-3 gestiscono il caso in cui il nodo \(z\) non ha figlio sinistro, le righe 4-5 gestiscono il caso in cui il nodo \(z\) ha un figlio sinistro, ma non un figlio destro, mentre le restanti righe gestiscono il caso in cui il nodo ha sia figlio destro che sinistro. Nello specifico, la riga 7 trova il nodo \(y\), successore di \(z\): poichè \(z\) ha un sottoalbero destro non vuoto, il suo successore deve essere il nodo di quel sottoalbero con la chiave più piccola (per questo motivo viene invocata la procedura \code{treeMinimum}). Come già detto, \(y\) non ha figlio sinistro, quindi bisogna staccare \(y\) dalla sua posizione corrente e metterlo al posto di \(z\). Se \(y\) è figlio destro di \(z\), le ultime tre righe sostituiscono \(z\) con \(y\), per poi sostituire il figlio sinistro di \(y\) con il figlio sinistro di \(z\). Se \(y\) non è figlio sinistro di \(z\), le righe 9-11 sostituiscono \(y\) con il figlio destro di \(y\) e cambiano il figlio destro di \(z\) nel figlio destro di \(y\). Tale procedura richiede un tempo di esecuzione nell'ordine di \(O(h)\), in un albero binario di ricerca alto \(h\).

\section{Alberi Red Black}
Gli alberi rosso nero sono strutture dati ad albero di ricerca binaria con un bit aggiuntivo di memoria per ogni nodo, che rappresenta il colore di tale nodo. Questa struttura dati, garantisce che nessun cammino semplice dalla radice dell'albero fino ad una sua qualsiasi foglia si più lungo del doppio di qualsiasi altro cammino: si dice, quindi, che l'albero è approssimativamente bilanciato. Ogni nodo dell'albero contiene ora gli attributi \code{key}, \code{left}, \code{right}, \code{parent} e \code{color}. Se un nodo non contiene riferimenti a figli o al nodo padre, il corrispondente attributo viene inizializzato con il valore \code{NIL}. In questo caso, i puntatori a \code{NIL} vengono trattati come puntatori a nodi (vuoti) esterni dell'albero, mentre i nodi che contengono informazioni sono trattati come nodi interni all'albero: dunque, tutte le foglie dell'albero sono nodi che non contengono nessuna informazione. In realtà, per semplificare le condizioni al contorno nello pseudocodice, si è soliti utilizzare un unico nodo sentinella inizializzato a \code{NIL}, in modo che per ogni albero \(T\), le sue foglie puntano al nodo \(T.nil\) di color nero.

I nodi dell'albero rosso nero vengono colorati tramite le seguenti regole:
\begin{enumerate}
  \item Ogni nodo è rosso o nero;
  \item La radice è nera;
  \item Ogni foglia (vuota - \code{NIL}) è nera;
  \item Se un nodo è rosso, allora entrambi i suoi figli sono neri;
  \item Per ogni nodo, tutti i cammini semplici, che vanno dal nodo alle sue foglie discendenti, contengono lo stesso numero di nodi neri.  
\end{enumerate}

Si definisce a questo proposito, altezza nera di un nodo \(x\), indicato con \(bh(x)\), il numero di nodi neri lungo un cammino semplice che inizia dal nodo \(x\) (non incluso). Per la proprietà degli alberi rosso nero, il concetto di altezza nera è ben definito in quanto tutti i cammini semplici che scendono dal nodo hanno lo stesso numero di nodi neri. In generale:

\begin{theorem}
  L'altezza massima di un albero rosso nero con \(n\) nodi è \(2\,log_2(n+1)\).
\end{theorem}

\noindent La conseguenza immediata di questo teorema è che le operazioni sugli insiemi dinamici possono tutte essere implementate in un tempo \(O(log_2\,n)\) negli alberi rosso neri, perchè possono essere eseguite nel tempo  \(O(h)\) in un albero binario di ricerca di altezza \(h\) e qualsiasi albero rosso nero di \(n\) nodi è un albero binario di ricerca di altezza \(O(log_2\,n)\).

\paragraph{Rotazione}
Le operazioni di \code{treeInsert} e \code{treeDelete} sugli alberi rosso nero, potrebbero violare le proprietà della struttura, proprio perchè modificano l'albero. Si rende quindi necessario ricalcolare i colori di qualche nodo dell'albero e anche la struttura dei puntatori, dopo la chiamata a una delle due procedure. La struttura dei puntatori viene modificata tramite una rotazione, ovvero un'operazione locale che preserva le proprietà degli alberi binari di ricerca. Quando si esegue una rotazione sinistra in un nodo \(x\), supponendo che il nodo \(y = x.right\) sia diverso da \code{NIL}, si fa "perno" sul collegamento tra \(x\) e \(y\): il nodo \(y\)diventa la nuova radice del sottoalbero, con \(x\) come figlio sinistro di \(y\) e il figlio sinistro di \(y\) come figlio destro di \(x\). In pseudocodifica:

\lstinputlisting{../docs/data_structures/RB_left_rotate.txt}

Il codice per la procedura \code{rightRotate} è simmetrico a quello appena analizzato. Entrambe le procedure vengono eseguite nel tempo \(O(1)\).

\paragraph{Inserimento}
L'inserimento di un nodo in un albero rosso nero viene eseguito tramite una versione leggermente modificata della procedura di inserimento analizzata per gli alberi binari di ricerca. Inoltre, per poter preservare le condizioni degli alberi rosso neri, è necessario utilizzare una seconda procedura che ricolora i nodi dell'albero in seguito alla chiamata della procedura di inserimento. In pseudocodifica:

\lstinputlisting{../docs/data_structures/RB_insert.txt}

Dunque, tramite questa procedura, il nodo \(z\) viene inserito nella posizione corretta all'interno dell'albero rosso nero, inizializzando gli attributi \code{left} e\code{right} a \code{NIL} (per rispettare la struttura dell'albero) e il suo colore a rosso. Dato che l'inserimento di questo nodo potrebbe aver causato la violazione delle proprietà fondamentali degli alberi rosso neri, viene chiamata la procedura di ripristino \code{RBFixup}, implementata con la seguente pseudocodifica:

\lstinputlisting{../docs/data_structures/rb_insert_fixup.txt}

Una volta chiamata la funzione di inserimento, sicuramente la proprietà 1 (ogni nodo è rosso o nero) e la proprietà 3 (ogni foglia è nera) sono rispettate in quanto i figli del nodo rosso appena inserito sono \(T.nil\). Anche la proprietà 5 (per ogni nodo, tutti i cammini semplici che vanno dal nodo alle sue foglie discendenti contengono lo stesso numero di nodi neri) è rispettata proprio perchè il nodo inserito nell'albero è di color rosso. Le uniche due proprietà che potrebbero non essere rispettate sono la 2 (la radice è nera) e la 4 (se un nodo è rosso, allora entrambi i suoi figli sono neri). Entrambe le possibili violazioni sono dovute al fatto che il nodo inserito viene colorato di rosso: infatti, se l'albero è vuoto, il nodo viene inserito alla radice violando la proprietà 2, mentre se il padre del nodo inserito è rosso, viene violata la proprietà 4. 

Dunque, nel caso ci fossero violazioni delle proprietà degli alberi rosso nero, ce ne sarebbe solo una e riguarderebbe le due proprietà di cui si è appena discusso. Esistono 3 casi possibili, segnati anche all'interno dello pseudocodice nei commenti, per la ricolorazione dei nodi:
\begin{enumerate}
  \item[Caso 1] Lo zio \(y\) di \(z\) è rosso: il caso 1 (righe 6-9) viene eseguito quando \(z.parent\) e \(y\) sono entrambi rossi. Poichè \(z.parent.parent\) è nero, è possibile colorare di nero \(z.parent\) e \(y\) risolvendo il problema per cui \(z\) e \(z.parent\) sono entrambi rossi. Si ricolora poi di rosso \(z.parent.parent\) per conservare la proprietà 5 e si ripete il ciclo \code{while} con \(z.parent.parent\) come nuovo nodo \(z\).
  \item[Caso 2] Lo zio \(y\) di \(z\) è nero e \(z\) è figlio destro: nel caso 2 (righe 12-13), lo zio di \(z\) è di colore nero e il nodo \(z\) è figlio destro. In questo caso è necessaria una semplice rotazione a sinistra per riportarsi immediatamente al caso 3. Una rotazione del genere non influisce nè sull'altezza dell'albero nè sulla proprietà 5.
  \item[Caso 3] Lo zio \(y\) di \(z\) è nero e \(z\) è figlio sinistro: nel caso 3 (righe 14-16), lo zio di \(z\) è sempre nero, ma il nodo \(z\) è figlio sinistro anzichè destro. In questo caso si applicano alcune modifiche sui colori e alcune rotazioni aggiuntive a destra per poter preservare le proprietà degli alberi rosso nero. 
\end{enumerate}

\paragraph{Rimozione}
La procedura di rimozione di un determinato nodo dall'albero rosso nero si basa sulla subroutine \code{transplant}, che deve essere opportunamente modificata in modo da adattarsi alla struttura degli alberi rosso nero. In pseudocodifica:

\lstinputlisting{../docs/data_structures/RB_transplant.txt}

Una volta introdotta questa procedura, è possibile analizzare l'algoritmo di rimozione, simile a quella analizzata per gli alberi di ricerca binaria, con l'unica differenza che si tiene traccia del nodo \(y\), che potrebbe violare le proprietà degli alberi rosso nero. Per evitare tali violazioni, si utilizza una seconda procedura di supporto che ha il compito di ricalcolare i colori dell'albero, in modo da rispettare le sue proprietà. In pseudocodifica:

\lstinputlisting{../docs/data_structures/RB_delete.txt}

\lstinputlisting{../docs/data_structures/RB_delete_fixup.txt}

\section{Grafi}
Un grafo \(G\) è una coppia \((V, E)\), in cui \(V\) è l'insieme finito dei vertici del grafo, mentre \(E\) è l'insieme degli archi di \(G\). Un arco è una relazione binaria su \(V\) che collega due vertici detti adiacenti: se un arco \(e\) connette due vertici \(u\) e \(v\), allora può essere rappresentato come la coppia \((u, v)\) dei vertici che connette. Da questo si ottiene che l'insieme \(E\subseteq V^2\) e quindi che \(0 \le |E| \le |V|^2\).

Esistono due tipologie di grafi, ovvero i grafi orientati e non orientati. Un grafo si dice non orientato quando la coppia \((u,v)\) è la stessa di \((v,u)\) e non c'è quindi la nozione di direzione da un nodo all'altro. D'altra parte, in un grafo orientato, la coppia \((u,v)\) è differente dall'arco \((v,u)\), in quanto si tiene conto della direzione di attraversamento. 

\subsection{Rappresentazione}

Esistono due metodi principali per la rappresentazione dei grafi: la prima consiste in una collezione di liste di adiacenza, mentre la seconda in una matrice di adiacenza. Entrambi i metodi possono essere applicati sia ai grafi orientati che non orientati. 

\paragraph{Rappresentazione con liste di adiacenza} Tale rappresentazione di un grafo \(G=(E,V)\) consiste in un array \(Adj\) di \(|V|\) liste concatenate, una per ogni vertice \(V\). Per ogni \(u\in V\), la lista di adicenza \(Adj[u]\) include tutti i vertici adiacenti a \(u\) in \(G\). Poichè le liste di adiacenza rappresentano gli archi di un grafo, nello pseudocodice si tratta l'array \(Adj\) come un attributo del grafo \(G\). 

Inoltre, Se \(G\) è un grafo orientato, la somma delle lunghezze di tutte le liste di adiacenza è esattamente \(|E|\), perchè un arco nella forma \((u,v)\) è rappresentato inserendo \(v\) in \(G.Adj[u]\). Al contrario, se \(G\) è un grafo non orientato, la somma delle lunghezze di tutte le liste di adiacenza è \(2|E|\), perchè se \((u,v)\) rappresenta un arco non orientato, allora \(u\) appare nella lista di adiacenza di \(v\) e viceversa. Per i grafi orientati e non, la rappresentazione con liste di adiacenza ha la proprietà di occupare una quantità di memoria \(\Theta(V+E)\). 

Lo svantaggio principale di questo metodo di rappresentazione risiede nel fatto che il metodo di ricerca è abbastanza inefficiente: infatti, per poter determinare se un determinato arco \((u,v)\) è presente nel grafo, è necessario cercare \(v\) nella lista di adiacenza \(G.Adj[u]\), operazione che richiede un tempo lineare.

\paragraph{Rappresentazione con matrice di adiacenza} Tale rappresentazione di un grafo \(G=(E,V)\) consiste in una matrice \(A =(a_{ij})\) di dimensione \(|V|\times |V|\) tale per cui:

\(
  a_{i,j} = 
  \begin{cases}
    1 & if\;(i, j)\in E\\
    0 & else  
  \end{cases}
\)

Per poter procedere con tale rappresentazione, è prima necessario che i vertici siano numerati in maniera arbitraria da 1 a \(|V|\). Si noti che, la matrice di adiacenza \(A\) per un grafo non orientato è uguale alla sua trasposta \(A^T\), per la proprietà principale dei grafi non orientati, per cui \((u,v) = (v,u)\).

Lo svantaggio maggiore nell'impiego di una matrice di adiacenza è l'utilizzo intensivo di memoria, nell'ordine di \(\Theta(|V|^2)\). Nonostante questo, per grafi di dimensione relativamente piccole, si preferisce utilizzare questo metodo a quello precedente, per la sua semplicità di utilizzo. In generale conviene utilizzare il metodo delle liste di adiacenza quando \(|E|\neq \Theta(|V|^2)\), cioè quando il grafo è sparso (ovvero quando il numero di nodi connessi non è molto grande), mentre se il grafo è completo (ovvero quando ogni nodo è connesso con i restanti), conviene utilizzare una matrice di adiacenza.

\subsection{Visita in Ampiezza}
La visita in ampiezza (o breadth-first search) è l'algoritmo più semplice di ricerca nei grafi. Dato un grafo \(G\) è un vertice distinto \(s\), detto sorgente, la visita in ampiezza ispeziona sistematicamente gli archi di \(G\) per scoprire tutti i vertici che sono raggiungibili da \(s\), calcolando la distanza da \(s\) a ciascun vertice raggiungibile. L'algoritmo è così chiamato perchè espande la frontiera fra i vertici scoperti e quelli ancora da scoprire in maniera uniforme lungo l'ampiezza della frontiera: l'algoritmo, infatti, scopre tutti i vertici che si trovano a distanza \(k\) da \(s\), prima di scoprire tutti i ivertici che si trovano a distanza \(k+1\).

Per tenere traccia del lavoro, la visita colora i vertici di bianco, grigio oppure nero. Inizialmente, tutti i vertici sono di colore bianco e possono diventare grigi e poi neri. Un vertice viene scoperto quando viene incontrato per la prima volta durante la visita, cessando di essere bianco. Tutti i vertici adiacenti ai vertici neri sono di colore grigio, il che significa che sono stati scoperti dall'algoritmo. I vertici grigi, invece, potrebbero presentare alcuni vertici adiacenti bianchi, che rappresentano la frontiera da scoprire: tali vertici sono tenuti in memoria in una coda (gestita dalla politica FIFO) e, ad ogni iterazione, si elimina dalla coda un elemento \(u\), visitando i vertici a lui adiacenti che sono ancora bianchi. Si noti che, se \(u.dist\) è la distanza del vertice \(u\) da \(s\), allora la distanza dei nodi bianchi adiacenti ad \(u\) è \(u.dist+1\).

In pseudocodifica:
\lstinputlisting[mathescape]{../docs/data_structures/graph_BFS.txt}

Informalmente, le righe 2-4 inizializzano ogni vertice, colorandolo di bianco, eccetto il vertice \(s\) che in riga 5 viene colorato di grigio, in quanto è il vertice sorgente già visitato ad inizio ricerca, e a cui viene assegnata la distanza 0. Le righe 7 e 8 inizializzano la coda \(Q\) inserendo il solo vertice \(s\). Il ciclo \code{while} di riga 10-16 viene reiterato fin tanto che ci sono ancora vertici grigi, la cui frontiera protrebbe ancora presentare vertici di colore bianco. La riga 10 determina il vertice grigio \(u\) che si trova in testa alla coda, rimuovendolo dalla coda stessa (\code{dequeue}), in modo da poter accedere ai suoi vertici adiacenti. Il ciclo \code{for}, di righe 11-15, esamina ciascun vertice \(v\) della lista di adiacenza di \(u\): se questo vertice è bianco, allora non è ancora stato scoperto e, quindi, l'algoritmo lo colora di grigio e lo inserisce nella coda dopo avergli assegnato il valore di distanza \(u.dist + 1\). Dopo aver esaminato ogni vertice nella lista di adiacenza di \(u\), tale vertice viene colorato di nero in riga 16.

Dato un grafo \(G=(V, E)\), il tempo di esecuzione dell'algoritmo BFS è \(O(|E|+|V|)\).

\subsection{Visita in Profondità}
La visita in profondità (o depth-first search) è un algoritmo che adotta una strategia differente rispetto al precedente: consiste, infatti, nel visitare il grafo sempre più in profondità se possibile. Nella visita in profondità, gli archi vengono ispezionati a partire dall'ultimo vertice \(v\) scoperto, che ha ancora archi non ispezionati nella sua lista di adiacenza. Questo processo continua fino a quando non sono stati scoperti tutti i vertici che sono raggiungibili dal vertice \(v\) da cui inizia la ricerca. Se rimane ancora qualche vertice da ispezionare, allora se ne sceglie uno nuovo come sorgente e si reitera il processo. 

Dunque, si può affermare che se l'algoritmo BFS si basa sulla strategia di visitare i vertici secondo una politica LIFO, l'algoritmo DFS si basa su una politica di tipo FIFO: una volta inserito un nodo in cima alla pila, si visitano tutti i vertici adiacenti relativi a quel nodo, prima di procedere alla visita dei vertici adiacenti del successivo. 

Come per il precedente algoritmo, anche in questo caso i vertici vengono colorati durante la loro visita, per indicarne lo stato. Inizialmente tutti i vertici sono colorati di bianco e nel momento in cui un determinato vertice viene visitato per la prima volta, questo viene colorato di grigio. Infine, un vertice è colorato di nero nel momento in vui sono ispezionati tutti i suoi vertici adiacenti. Oltre alla lista di adiacenza e al colore, i vertici all'interno di un grafo visitato in profondità, contengono anche due informazioni temporali: la prima, memorizzata in \(v.d\), registra il momento in cui il vertice viene scoperto e colorato di grigio, mentre le seconda, memorizzata in \(v.f\), registra il momento in cui la visita completa l'ispezione della lista di adiacenza di \(v\) e viene colorato di nero. Quindi, un vertice \(v\) è bianco prima del tempo \(v.d\), grigio fra il tempo \(v.d\) e \(v.f\), nero successivamente. Queste informazioni aggiuntive servono per agevolare la scrittura di procedure e sono utilizzate anche da parte di algoritmi più avanzati. 

Si introduce di seguito la procedura in pseudocodifica che realizza la strategia di visita in profondità:

\lstinputlisting{../docs/data_structures/graph_DFS.txt}

La procedura imposta, in righe 2-3, il colore di tutti i vertici di bianco, per poi inizializzare una variabile globale \code{time},tramite cui si memorizzano le informazioni temporali precedentemente discusse. Le righe successive servono ad ispezionare in profondità tutti i vertici che hanno colore bianco, tramite la procedura di supporto \code{DFSVisit}, introdotta di seguito.

\lstinputlisting{../docs/data_structures/graph_DFS_visit.txt}

In ogni chiamata della procedura \code{DFSVisit}, il vertice \(u\) passato come argomento è inizialmente bianco, quindi gli si assegna subito il colore grigio dopo aver assegnato al vertice il tempo di scoperta (\(u.d\)) il tempo incrementato di una unità (righe 2-4). Subito dopo, il ciclo \code{for} di righe 5-7 esplora tutti i vertici \(v\) di colore bianco adiacenti ad \(u\) e chiama ricorsivamente la procedura in modo da visitare il vertice \(v\) e i vertici a lui adiacenti, sempre se di colore bianco. Dopo aver terminato la visita in profondità di tutti i vertici a partire dal vertice sorgente \(u\), il colore di tale vertice viene cambiato in nero e si assegna al tempo di fine esplorazione \(u.f\) il valore temporale, dopo averlo nuovamente incrementato di una unità (righe 8-10).

Anche in questo caso, come per il procedimento precedente, il tempo medio di esecuzione dell'algoritmo di ispezione in profondità è \(\Theta(|V|+|E|)\).

\subsection{Ordinamento Topologico}
La visita in profondità può essere utilizzata per eseguire l'ordinamento  topologico di un determinato grafo orientato aciclico (detto anche DAG - Directed Acyclic Graph). Un ordinamento topologico di un dag \(G=(V,E)\) è un ordinamento lineare di tutti i suoi vertici, tale che se \(G\) contiene un arco \((u,v)\), allora \(u\) appare prima di \(v\) nell'ordinamento. Un ordinamento topologico di un grafo può essere visto come un ordinamento dei suoi vertici lungo una linea orizzontale ion modo che tutti gli archi orientati siano diretti da sinistra verso destra: intuitivamente, questo tipo di ordinamento, serve a rappresentare la precedenza di determinati eventi. 

In pseudocodifica:

\lstinputlisting[mathescape]{../docs/data_structures/graph_topsort.txt}
\lstinputlisting{../docs/data_structures/graph_topsort_visit.txt}

L'idea di questo algoritmo è quella di visitare il dag con l'algoritmo di vista DFS e, quando un vertice viene colorato di nero, lo si inserisce in testa alla lista \(L\) che rappresenta tutti i nodi ordinati. Una volta completata la visita di ogni vertice, la lista ottenuta rappresenta l'ordinamento topologico del grafo. 

Anche in questo caso, l'algoritmo impiega un tempo di esecuzione medio \(\Theta(|V|+|E|)\).  
